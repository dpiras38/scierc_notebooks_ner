{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U transformers peft accelerate optimum\n",
    "%pip install bitsandbytes\n",
    "#!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/\n",
    "%pip install nltk\n",
    "%git clone https://github.com/PanQiWei/AutoGPTQ\n",
    "%cd AutoGPTQ\n",
    "%pip install .\n",
    "%cd ..\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTQConfig\n",
    "\n",
    "# Caricamento del modello base\n",
    "\n",
    "base_model_id = \"TheBloke/Mistral-7B-v0.1-GPTQ\"\n",
    "quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id,quantization_config=quantization_config_loading, device_map=\"auto\", trust_remote_code=True)\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)\n",
    "\n",
    "# Prompt e frase di input\n",
    "question = \"An extension of our method to space-time interest point detection for action classification is also presented\"\n",
    "eval_prompt = f\"\"\"### Question: Identify and extract without rephrasing all entities that belongs to the categories Method, Metric, Material, Task, OtherScientificTerm, Generic from the following sentence: \"{question}\"\n",
    "Write the answer in this format: Metric: entity, entity; Method: entity, entity; Material: entity, entity; Task: entity, entity; OtherScientificTerm: entity, entity; Generic: entity, entity;\n",
    "These are the annotation guideline to extract entities:\n",
    "Task are Applications, problems to solve, systems to construct;\n",
    "Method are Methods , models, systems to use, or tools, components of a system;\n",
    "Evaluation Metric are Metrics, measures, or entities that can express quality of a system/method;\n",
    "Material are Data, datasets, resources, Corpus, Knowledge base;\n",
    "OtherScientificTerms are Phrases that are a scientific terms but do not fall into any of the above classes;\n",
    "Generic are General terms or pronouns that may refer to a entity but are not themselves informative.\n",
    "### Answer:\"\"\"\n",
    "\n",
    "\n",
    "# Caricamento del modello fine-tuned\n",
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"/content/drive/MyDrive/Tesi/models/mistral-ner-finetune-def/checkpoint-200\")\n",
    "\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "  result = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens= 1020,do_sample = False)[0], skip_special_tokens=True)\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTQConfig\n",
    "\n",
    "# Caricamento del modello base\n",
    "base_model_id = \"TheBloke/Mistral-7B-v0.1-GPTQ\"\n",
    "quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id,quantization_config=quantization_config_loading, device_map=\"auto\", trust_remote_code=True)\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)\n",
    "\n",
    "# Caricamento del modello fine-tuned\n",
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"/content/drive/MyDrive/Tesi/models/mistral-ner-finetune-new-prompt/checkpoint-348\")\n",
    "ft_model.eval()\n",
    "\n",
    "\n",
    "# Path del file di output\n",
    "path_result = \"/content/drive/MyDrive/Tesi/result/result_mistral_new_prompt.json\"\n",
    "path_dataset = \"/content/drive/MyDrive/Tesi/dataset/scierc_test_inc.json\"\n",
    "\n",
    "import json\n",
    "\n",
    "# Per ogni riga del dataset si effettua la predizione e si scrive il risultato nel file di output\n",
    "with open(path_dataset) as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        question = data[\"input\"]\n",
    "        eval_prompt = f\"\"\"### Question: Identify and extract without rephrasing all entities that belongs to the categories Method, Metric, Material, Task, OtherScientificTerm, Generic from the following sentence: \"{question}\"\n",
    "Write the answer in this format: Metric: entity, entity; Method: entity, entity; Material: entity, entity; Task: entity, entity; OtherScientificTerm: entity, entity; Generic: entity, entity;\n",
    "These are the annotation guideline to extract entities:\n",
    "Task are Applications, problems to solve, systems to construct;\n",
    "Method are Methods , models, systems to use, or tools, components of a system;\n",
    "Evaluation Metric are Metrics, measures, or entities that can express quality of a system/method;\n",
    "Material are Data, datasets, resources, Corpus, Knowledge base;\n",
    "OtherScientificTerms are Phrases that are a scientific terms but do not fall into any of the above classes;\n",
    "Generic are General terms or pronouns that may refer to a entity but are not themselves informative.\n",
    "### Answer:\"\"\"\n",
    "        model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "        result = eval_tokenizer.decode(ft_model.generate(inputs = model_input, max_new_tokens= 200,do_sample = False)[0], skip_special_tokens=True)\n",
    "        with open(path_result, 'a') as outfile:\n",
    "          json_object = {\"prediction\": result}\n",
    "          json.dump(json_object, outfile)\n",
    "          outfile.write('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
