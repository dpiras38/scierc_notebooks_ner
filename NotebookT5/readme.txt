There are three different notebooks: one for fine-tuning, one for generating responses with the fine-tuned model, and the last one for span-based evaluation. These notebooks can be used with both the T5 and FLAN T5 models.

The fine-tuning notebook is already set up and configured to be run. You need to change the paths for the training and validation datasets, the path of the directory where all the various fine-tuned model checkpoints will be saved, and optionally the name of the chosen model. The available FLAN T5 models can be found at this link: FLAN T5 models, while the T5 models are available at this link: T5 models. You can also modify the global training parameters as needed, such as batch size, to ensure that the model is properly loaded into the available GPU VRAM.

The response generation notebook offers two alternatives: in the first cell, you can generate a single response using the generate_question function by passing a string containing the input sentence and the path to the fine-tuned model. In the other cell, you can generate a JSON file containing all the responses the model generates using a test set. You will need to change the paths for the dataset, the fine-tuned model, and the directory where the results will be saved.

The last notebook allows you to generate an evaluation on the test set using span-based evaluation. You only need to pass the file paths for the dataset and the results to the functions, and they will handle the calculation of the metrics. It is necessary to run the first cell to ensure that the remaining functions execute correctly.

The folder already contains the dataset files: there are training, validation, and test set files in three different versionsâ€”one with encapsulation, one without encapsulation, and one without differences (which includes the other two versions).