{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U transformers peft accelerate optimum\n",
    "%pip install bitsandbytes\n",
    "%pip install auto-gptq\n",
    "%pip install nltk\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTQConfig\n",
    "\n",
    "# Caricamento del modello base\n",
    "\n",
    "base_model_id = \"TheBloke/Mistral-7B-v0.1-GPTQ\"\n",
    "quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id,quantization_config=quantization_config_loading, device_map=\"auto\", trust_remote_code=True)\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)\n",
    "\n",
    "# Prompt e frase di input\n",
    "question = \"Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- \"\n",
    "eval_prompt = f\"\"\"Extract the entities for the following labels from the given text and provide the results in JSON format\n",
    "- Entities must be extracted exactly as mentioned in the text.\n",
    "- Return each entity under its label without creating new labels.\n",
    "- Provide a list of entities for each label, ensuring that if no entities are found for a label, an empty list is returned.\n",
    "- Accuracy and relevance in your responses are key.\n",
    "\n",
    "Lables and their Descriptions:\n",
    "- Task: applications, problems to solve, systems to construct.\n",
    "- Method: methods, models, systems to use, tools, components of a system.\n",
    "- Metric: metrics, measures, or entities that can express quality of a system/method.\n",
    "- Material: data, datasets, resources, Corpus, Knowledge base.\n",
    "- OtherScientificTerm: phrases that are a scientific terms but do not fall into any of the above classes.\n",
    "- Generic: general terms or pronouns that may refer to a entity but are not themselves informative.\n",
    "\n",
    "### Input text: {question}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "\n",
    "# Caricamento del modello fine-tuned\n",
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"Andro9669/Mistral-7b-ner\")\n",
    "\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "  result = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens= 1020,do_sample = False)[0], skip_special_tokens=True)\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTQConfig\n",
    "\n",
    "# Caricamento del modello base\n",
    "base_model_id = \"TheBloke/Mistral-7B-v0.1-GPTQ\"\n",
    "quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id,quantization_config=quantization_config_loading, device_map=\"auto\", trust_remote_code=True)\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)\n",
    "\n",
    "# Caricamento del modello fine-tuned\n",
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"Andro9669/Mistral-7b-ner\")\n",
    "ft_model.eval()\n",
    "\n",
    "\n",
    "# Path del file di output\n",
    "path_result = \"/content/drive/MyDrive/Tesi/result/result_mistral_new_prompt.json\"\n",
    "path_dataset = \"/content/drive/MyDrive/Tesi/dataset/scierc_test_inc.json\"\n",
    "\n",
    "import json\n",
    "\n",
    "# Per ogni riga del dataset si effettua la predizione e si scrive il risultato nel file di output\n",
    "with open(path_dataset) as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        question = data[\"input\"]\n",
    "        eval_prompt = f\"\"\"Extract the entities for the following labels from the given text and provide the results in JSON format\n",
    "- Entities must be extracted exactly as mentioned in the text.\n",
    "- Return each entity under its label without creating new labels.\n",
    "- Provide a list of entities for each label, ensuring that if no entities are found for a label, an empty list is returned.\n",
    "- Accuracy and relevance in your responses are key.\n",
    "\n",
    "Lables and their Descriptions:\n",
    "- Task: applications, problems to solve, systems to construct.\n",
    "- Method: methods, models, systems to use, tools, components of a system.\n",
    "- Metric: metrics, measures, or entities that can express quality of a system/method.\n",
    "- Material: data, datasets, resources, Corpus, Knowledge base.\n",
    "- OtherScientificTerm: phrases that are a scientific terms but do not fall into any of the above classes.\n",
    "- Generic: general terms or pronouns that may refer to a entity but are not themselves informative.\n",
    "\n",
    "### Input text: {question}\n",
    "\n",
    "### Response:\"\"\"\n",
    "        model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "        result = eval_tokenizer.decode(ft_model.generate(inputs = model_input, max_new_tokens= 200,do_sample = False)[0], skip_special_tokens=True)\n",
    "        with open(path_result, 'a') as outfile:\n",
    "          json_object = {\"prediction\": result}\n",
    "          json.dump(json_object, outfile)\n",
    "          outfile.write('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
